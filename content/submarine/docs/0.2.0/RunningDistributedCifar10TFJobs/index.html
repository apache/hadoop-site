
<!DOCTYPE html>

<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Machine learning engine for Hadoop">
    <meta name="keywords" content="hadoop, submarine, machine learning, tensorflow, deep learning"/>
    <meta name="robots" content="index,follow"/>
    <meta name="language" content="en"/>

    <title>Apache Hadoop Submarine</title>

    <base href="/submarine/">

    <link rel="canonical" href="https://hadoop.apache.org/submarine">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
          integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">

</head>

<body>


<div class="topnav">
    <div class="container">
        <ul class="breadcrumb col-md-6">
            <li>
                <img class="asf-logo" src="asf_feather.png"/>
                <a  href="https://www.apache.org">Apache Software Foundation</span></a>
            </li>
            <li><a href="https://hadoop.apache.org">Apache Hadoop&trade;</a></li>
            <li><a href="/submarine/">Submarine&trade;</a></li>
        </ul>
        <div class="col-md-6">
            <ul class="pull-right breadcrumb">
                <li><a href="https://www.apache.org/licenses/">License</a></li>
                <li><a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
                <li><a href="https://www.apache.org/foundation/thanks.html">Thanks</a></li>
                <li><a href="https://www.apache.org/security/">Security</a></li>
        </ul>
        </div>
    </div>

    <nav class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                        data-target="#ratis-menu" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>

            <div id="ratis-menu" class="collapse navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    
                    <li><a href="docs/Index">Documentation</a></li>
                    <li><a href="downloads">Download</a></li>
                    <li><a href="ecosystem">Ecosystem</a></li>
                    <li><a href="#qa">Q&A</a></li>
                    <li><a href="https://cwiki.apache.org/confluence/display/HADOOP/Submarine+Contributor+Guide">Wiki</a></li>
                    <li><a href="activity">Activity</a></li>
                    <li><a href="team">Team</a></li>
                </ul>
            </div>

    </nav>

    <div style="max-height: 200px; overflow: hidden;">
      <img src="cloud.png" style="width: 100%; left:0px;"/>
    </div>

</div>

</div>

<div class="container">
  

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at
   https://www.apache.org/licenses/LICENSE-2.0
   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<h1 id="cifar10-tensorflow-estimator-example-with-yarn-service">Cifar10 Tensorflow Estimator Example With YARN Service</h1>

<h2 id="prepare-data-for-training">Prepare data for training</h2>

<p>CIFAR-10 is a common benchmark in machine learning for image recognition. Below example is based on CIFAR-10 dataset.</p>

<p>1) Checkout <a href="https://github.com/tensorflow/models/:">https://github.com/tensorflow/models/:</a></p>

<pre><code>git clone https://github.com/tensorflow/models/
</code></pre>

<p>2) Go to <code>models/tutorials/image/cifar10_estimator</code></p>

<p>3) Generate data by using following command: (required Tensorflow installed)</p>

<pre><code>python generate_cifar10_tfrecords.py --data-dir=cifar-10-data
</code></pre>

<p>4) Upload data to HDFS</p>

<pre><code>hadoop fs -put cifar-10-data/ /dataset/cifar-10-data
</code></pre>

<p><strong>Warning:</strong></p>

<p>Please note that YARN service doesn&rsquo;t allow multiple services with the same name, so please run following command</p>

<pre><code>yarn application -destroy &lt;service-name&gt;
</code></pre>

<p>to delete services if you want to reuse the same service name.</p>

<h2 id="prepare-docker-images">Prepare Docker images</h2>

<p>Refer to <a href="docs/0.2.0/WriteDockerfileTF">Write Dockerfile</a> to build a Docker image or use prebuilt one:</p>

<ul>
<li>hadoopsubmarine/tensorflow1.13.1-hadoop3.1.2-cpu:1.0.0</li>
<li>hadoopsubmarine/tensorflow1.13.1-hadoop3.1.2-gpu:1.0.0</li>
</ul>

<h2 id="run-tensorflow-jobs">Run Tensorflow jobs</h2>

<h3 id="run-standalone-training">Run standalone training</h3>

<pre><code>SUBMARINE_VERSION=0.2.0
CLASSPATH=`path-to/hadoop classpath --glob`:path-to/hadoop-submarine-core-${SUBMARINE_VERSION}.jar:
path-to/hadoop-submarine-yarnservice-runtime-${SUBMARINE_VERSION}.jar:path-to/hadoop-submarine-tony-
runtime-${SUBMARINE_VERSION}.jar \
java org.apache.hadoop.yarn.submarine.client.cli.Cli job run \
   --name tf-job-001 --verbose --docker_image &lt;image&gt; \
   --input_path hdfs://default/dataset/cifar-10-data \
   --env DOCKER_JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/
   --env DOCKER_HADOOP_HDFS_HOME=/hadoop-current
   --num_workers 1 --worker_resources memory=8G,vcores=2,gpu=1 \
   --worker_launch_cmd &quot;cd /test/models/tutorials/image/cifar10_estimator &amp;&amp; python cifar10_main.py --data-dir=%input_path% --job-dir=%checkpoint_path% --train-steps=10000 --eval-batch-size=16 --train-batch-size=16 --num-gpus=2 --sync&quot; \
   --tensorboard --tensorboard_docker_image tf-1.13.1-cpu:0.0.1
</code></pre>

<p>Explanations:</p>

<ul>
<li>When access of HDFS is required, the two environments are required to indicate: DOCKER_JAVA_HOME and DOCKER_HADOOP_HDFS_HOME to access libhdfs libraries <em>inside Docker image</em>. We will try to eliminate specifying this in the future.</li>
<li>Docker image for worker and tensorboard can be specified separately. For this case, Tensorboard doesn&rsquo;t need GPU, so we will use cpu Docker image for Tensorboard. (Same for parameter-server in the distributed example below).</li>
</ul>

<h3 id="run-distributed-training">Run distributed training</h3>

<pre><code>SUBMARINE_VERSION=0.2.0
CLASSPATH=`path-to/hadoop classpath --glob`:path-to/hadoop-submarine-core-${SUBMARINE_VERSION}.jar:
path-to/hadoop-submarine-yarnservice-runtime-${SUBMARINE_VERSION}.jar:path-to/hadoop-submarine-tony-
runtime-${SUBMARINE_VERSION}.jar \
java org.apache.hadoop.yarn.submarine.client.cli.Cli job run \
   --name tf-job-001 --verbose --docker_image tf-1.13.1-gpu:0.0.1 \
   --input_path hdfs://default/dataset/cifar-10-data \
   --env(s) (same as standalone)
   --num_workers 2 \
   --worker_resources memory=8G,vcores=2,gpu=1 \
   --worker_launch_cmd &quot;cd /test/models/tutorials/image/cifar10_estimator &amp;&amp; python cifar10_main.py --data-dir=%input_path% --job-dir=%checkpoint_path% --train-steps=10000 --eval-batch-size=16 --train-batch-size=16 --num-gpus=2 --sync&quot;  \
   --ps_docker_image tf-1.13.1-cpu:0.0.1 \
   --num_ps 1 --ps_resources memory=4G,vcores=2,gpu=0  \
   --ps_launch_cmd &quot;cd /test/models/tutorials/image/cifar10_estimator &amp;&amp; python cifar10_main.py --data-dir=%input_path% --job-dir=%checkpoint_path% --num-gpus=0&quot; \
   --tensorboard --tensorboard_docker_image tf-1.13.1-cpu:0.0.1
</code></pre>

<p>Explanations:</p>

<ul>
<li><code>&gt;1</code> num_workers indicates it is a distributed training.</li>
<li>Parameters / resources / Docker image of parameter server can be specified separately. For many cases, parameter server doesn&rsquo;t require GPU.</li>
</ul>

<p>For the meaning of the individual parameters, see the <a href="docs/0.2.0/QuickStart">QuickStart</a> page!</p>

<p><em>Outputs of distributed training</em></p>

<p>Sample output of master:</p>

<pre><code>...
allow_soft_placement: true
, '_tf_random_seed': None, '_task_type': u'master', '_environment': u'cloud', '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe77cb15050&gt;, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
...
2018-05-06 22:29:14.656022: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -&gt; {0 -&gt; localhost:8000}
2018-05-06 22:29:14.656097: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; ps-0.distributed-tf.root.tensorflow.site:8000}
2018-05-06 22:29:14.656112: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; worker-0.distributed-tf.root.tensorflow.site:8000}
2018-05-06 22:29:14.659359: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:8000
...
INFO:tensorflow:Restoring parameters from hdfs://default/tmp/cifar-10-jobdir/model.ckpt-0
INFO:tensorflow:Evaluation [1/625]
INFO:tensorflow:Evaluation [2/625]
INFO:tensorflow:Evaluation [3/625]
INFO:tensorflow:Evaluation [4/625]
INFO:tensorflow:Evaluation [5/625]
INFO:tensorflow:Evaluation [6/625]
...
INFO:tensorflow:Validation (step 1): loss = 1220.6445, global_step = 1, accuracy = 0.1
INFO:tensorflow:loss = 6.3980675, step = 0
INFO:tensorflow:loss = 6.3980675, learning_rate = 0.1
INFO:tensorflow:global_step/sec: 2.34092
INFO:tensorflow:Average examples/sec: 1931.22 (1931.22), step = 100
INFO:tensorflow:Average examples/sec: 354.236 (38.6479), step = 110
INFO:tensorflow:Average examples/sec: 211.096 (38.7693), step = 120
INFO:tensorflow:Average examples/sec: 156.533 (38.1633), step = 130
INFO:tensorflow:Average examples/sec: 128.6 (38.7372), step = 140
INFO:tensorflow:Average examples/sec: 111.533 (39.0239), step = 150
</code></pre>

<p>Sample output of worker:</p>

<pre><code>, '_tf_random_seed': None, '_task_type': u'worker', '_environment': u'cloud', '_is_chief': False, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc2a490b050&gt;, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
...
2018-05-06 22:28:45.807936: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -&gt; {0 -&gt; master-0.distributed-tf.root.tensorflow.site:8000}
2018-05-06 22:28:45.808040: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; ps-0.distributed-tf.root.tensorflow.site:8000}
2018-05-06 22:28:45.808064: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:8000}
2018-05-06 22:28:45.809919: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:8000
...
INFO:tensorflow:loss = 5.319096, step = 0
INFO:tensorflow:loss = 5.319096, learning_rate = 0.1
INFO:tensorflow:Average examples/sec: 49.2338 (49.2338), step = 10
INFO:tensorflow:Average examples/sec: 52.117 (55.3589), step = 20
INFO:tensorflow:Average examples/sec: 53.2754 (55.7541), step = 30
INFO:tensorflow:Average examples/sec: 53.8388 (55.6028), step = 40
INFO:tensorflow:Average examples/sec: 54.1082 (55.2134), step = 50
INFO:tensorflow:Average examples/sec: 54.3141 (55.3676), step = 60
</code></pre>

<p>Sample output of ps:</p>

<pre><code>...
, '_tf_random_seed': None, '_task_type': u'ps', '_environment': u'cloud', '_is_chief': False, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4be54dff90&gt;, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
...
2018-05-06 22:28:42.562316: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -&gt; {0 -&gt; master-0.distributed-tf.root.tensorflow.site:8000}
2018-05-06 22:28:42.562408: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:8000}
2018-05-06 22:28:42.562433: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; worker-0.distributed-tf.root.tensorflow.site:8000}
2018-05-06 22:28:42.564242: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:8000
</code></pre>

<h4 id="notes">Notes:</h4>

<p>When using YARN native service runtime, you can view multiple job training history like from the <code>Tensorboard</code> link:</p>

<p><img src="./images/multiple-tensorboard-jobs.png" alt="alt text" title="Tensorboard for multiple jobs" /></p>

<h2 id="run-tensorboard-to-monitor-your-jobs">Run tensorboard to monitor your jobs</h2>

<pre><code class="language-shell"># Cleanup previous tensorboard service if needed

SUBMARINE_VERSION=0.2.0
CLASSPATH=`path-to/hadoop classpath --glob`:path-to/hadoop-submarine-core-${SUBMARINE_VERSION}.jar:path-to/hadoop-submarine-yarnservice-runtime-${SUBMARINE_VERSION}.jar:path-to/hadoop-submarine-tony-runtime-${SUBMARINE_VERSION}.jar \
java org.apache.hadoop.yarn.submarine.client.cli.Cli job run \
  --name tensorboard-service \
  --verbose \
  --docker_image &lt;your-docker-image&gt; \
  --env DOCKER_JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/ \
  --env DOCKER_HADOOP_HDFS_HOME=/hadoop-current \
  --checkpoint_path hdfs://default/tmp/cifar-10-jobdir \
  --worker_resources memory=2G,vcores=2 \
  --worker_launch_cmd &quot;pwd&quot; \
  --tensorboard
</code></pre>

</div>

<footer>
    <div class="container">

        <div class="col-md-12 trademark">
            <p>&copy; 2019 <a href="http://apache.org">The Apache Software Foundation</a>,<br/>
                Apache, Apache Hadoop, the Apache feather logo, are trademarks of The Apache Software Foundation.
            <p>
        </div>
    </div>
</footer>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"
        integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS"
        crossorigin="anonymous"></script>


</body>
</html>

