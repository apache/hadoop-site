<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--
 | Generated by Apache Maven Doxia at 2018-08-02
 | Rendered using Apache Maven Stylus Skin 1.5
-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop 3.1.1 &#x2013; HDFS Disk Balancer</title>
    <style type="text/css" media="all">
      @import url("./css/maven-base.css");
      @import url("./css/maven-theme.css");
      @import url("./css/site.css");
    </style>
    <link rel="stylesheet" href="./css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20180802" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                </head>
  <body class="composite">
    <div id="banner">
                        <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        <img src="https://hadoop.apache.org/images/hadoop-logo.jpg" alt="" />
                </a>
                              <a href="http://www.apache.org/" id="bannerRight">
                                        <img src="https://www.apache.org/images/asf_logo_wide.png" alt="" />
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                   <div class="xleft">
                          <a href="http://www.apache.org/" class="externalLink">Apache</a>
        &gt;
                  <a href="http://hadoop.apache.org/" class="externalLink">Hadoop</a>
        &gt;
                  <a href="../index.html">Apache Hadoop Project Dist POM</a>
        &gt;
                  <a href="index.html">Apache Hadoop 3.1.1</a>
        &gt;
        HDFS Disk Balancer
        </div>
            <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://git-wip-us.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
            |
                <a href="http://hadoop.apache.org/" class="externalLink">Apache Hadoop</a>
              
                                   &nbsp;| Last Published: 2018-08-02
              &nbsp;| Version: 3.1.1
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                   <h5>General</h5>
                  <ul>
                  <li class="none">
                  <a href="../../index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/ClusterSetup.html">Cluster Setup</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CommandsManual.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/FileSystemShell.html">FileSystem Shell</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Compatibility.html">Compatibility Specification</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/DownstreamDev.html">Downstream Developer's Guide</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/AdminCompatibilityGuide.html">Admin Compatibility Guide</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/InterfaceClassification.html">Interface Classification</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/filesystem/index.html">FileSystem Specification</a>
            </li>
          </ul>
                       <h5>Common</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CLIMiniCluster.html">CLI Mini Cluster</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/NativeLibraries.html">Native Libraries</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Superusers.html">Proxy User</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/RackAwareness.html">Rack Awareness</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/SecureMode.html">Secure Mode</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/ServiceLevelAuth.html">Service Level Authorization</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/HttpAuthentication.html">HTTP Authentication</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CredentialProviderAPI.html">Credential Provider API</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-kms/index.html">Hadoop KMS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Tracing.html">Tracing</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/UnixShellGuide.html">Unix Shell Guide</a>
            </li>
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">User Guide</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">NameNode HA With QJM</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">NameNode HA With NFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/Federation.html">Federation</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ViewFs.html">ViewFs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html">Snapshots</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html">Edits Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html">Image Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">Permissions and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html">Quotas and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/LibHdfs.html">libhdfs (C API)</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS (REST API)</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-hdfs-httpfs/index.html">HttpFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">Short Circuit Local Reads</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html">Centralized Cache Management</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html">NFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">Rolling Upgrade</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html">Extended Attributes</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html">Transparent Encryption</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsMultihoming.html">Multihoming</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Storage Policies</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/MemoryStorage.html">Memory Storage Support</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/SLGUserGuide.html">Synthetic Load Generator</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html">Erasure Coding</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSDiskbalancer.html">Disk Balancer</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsUpgradeDomain.html">Upgrade Domain</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsDataNodeAdminGuide.html">DataNode Admin</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs-rbf/HDFSRouterFederation.html">Router Federation</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsProvidedStorage.html">Provided Storage</a>
            </li>
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">Tutorial</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduce_Compatibility_Hadoop1_Hadoop2.html">Compatibility with 1.x</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html">Encrypted Shuffle</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html">Pluggable Shuffle/Sort</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html">Distributed Cache Deploy</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/SharedCacheSupport.html">Support for YARN Shared Cache</a>
            </li>
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest.html">MR Application Master</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html">MR History Server</a>
            </li>
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YARN.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YarnCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/FairScheduler.html">Fair Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRestart.html">ResourceManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">ResourceManager HA</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceModel.html">Resource Model</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeLabel.html">Node Labels</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html">Web Application Proxy</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html">Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServiceV2.html">Timeline Service V.2</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html">Writing YARN Applications</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html">YARN Application Security</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManager.html">NodeManager</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/DockerContainers.html">Running Applications in Docker Containers</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html">Using CGroups</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/SecureContainer.html">Secure Containers</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/registry/index.html">Registry</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ReservationSystem.html">Reservation System</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/GracefulDecommission.html">Graceful Decommission</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/OpportunisticContainers.html">Opportunistic Containers</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/Federation.html">YARN Federation</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/SharedCache.html">Shared Cache</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/UsingGpus.html">Using GPU</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/UsingFPGA.html">Using FPGA</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/PlacementConstraints.html">Placement Constraints</a>
            </li>
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html">Introduction</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html">Resource Manager</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManagerRest.html">Node Manager</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html#Timeline_Server_REST_API_v1">Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServiceV2.html#Timeline_Service_v.2_REST_API">Timeline Service V.2</a>
            </li>
          </ul>
                       <h5>YARN Service</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/yarn-service/Overview.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/yarn-service/QuickStart.html">QuickStart</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/yarn-service/Concepts.html">Concepts</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/yarn-service/YarnServiceAPI.html">Yarn Service API</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/yarn-service/ServiceDiscovery.html">Service Discovery</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/yarn-service/SystemServices.html">System Services</a>
            </li>
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-aliyun/tools/hadoop-aliyun/index.html">Aliyun OSS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-aws/tools/hadoop-aws/index.html">Amazon S3</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-azure/index.html">Azure Blob Storage</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-azure-datalake/index.html">Azure Data Lake Storage</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-openstack/index.html">OpenStack Swift</a>
            </li>
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-auth/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/Examples.html">Examples</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/Configuration.html">Configuration</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/BuildingIt.html">Building</a>
            </li>
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-streaming/HadoopStreaming.html">Hadoop Streaming</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-archives/HadoopArchives.html">Hadoop Archives</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-archive-logs/HadoopArchiveLogs.html">Hadoop Archive Logs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-distcp/DistCp.html">DistCp</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-gridmix/GridMix.html">GridMix</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-rumen/Rumen.html">Rumen</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-resourceestimator/ResourceEstimator.html">Resource Estimator Service</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-sls/SchedulerLoadSimulator.html">Scheduler Load Simulator</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Benchmarking.html">Hadoop Benchmarking</a>
            </li>
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/release/index.html">Changelog and Release Notes</a>
            </li>
                  <li class="none">
                  <a href="../../api/index.html">Java API docs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/UnixShellAPI.html">Unix Shell API</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Metrics.html">Metrics</a>
            </li>
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs-rbf/hdfs-rbf-default.xml">hdfs-rbf-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/DeprecatedProperties.html">Deprecated Properties</a>
            </li>
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="./images/logos/maven-feather.png"/>
        </a>
                       
                               </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!---
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<h1>HDFS Disk Balancer</h1>
<ul>
<li><a href="#Overview">Overview</a></li>
<li><a href="#Architecture">Architecture</a></li>
<li><a href="#Commands">Commands</a>
<ul>
<li><a href="#Plan">Plan</a></li>
<li><a href="#Execute">Execute</a></li>
<li><a href="#Query">Query</a></li>
<li><a href="#Cancel">Cancel</a></li>
<li><a href="#Report">Report</a></li></ul></li>
<li><a href="#Settings">Settings</a></li>
<li><a href="#a.7C_Setting_.7C_Description_.7C_.7C:.E2.80.94-_.7C:.E2.80.94-_.7C_.7Cdfs.disk.balancer.enabled.7C_This_parameter_controls_if_diskbalancer_is_enabled_for_a_cluster._if_this_is_not_enabled.2C_any_execute_command_will_be_rejected_by_the_datanode.The_default_value_is_false..7C_.7Cdfs.disk.balancer.max.disk.throughputInMBperSec_.7C_This_controls_the_maximum_disk_bandwidth_consumed_by_diskbalancer_while_copying_data._If_a_value_like_10MB_is_specified_then_diskbalancer_on_the_average_will_only_copy_10MB.2FS._The_default_value_is_10MB.2FS..7C_.7Cdfs.disk.balancer.max.disk.errors.7C_sets_the_value_of_maximum_number_of_errors_we_can_ignore_for_a_specific_move_between_two_disks_before_it_is_abandoned._For_example.2C_if_a_plan_has_3_pair_of_disks_to_copy_between_.2C_and_the_first_disk_set_encounters_more_than_5_errors.2C_then_we_abandon_the_first_copy_and_start_the_second_copy_in_the_plan._The_default_value_of_max_errors_is_set_to_5..7C_.7Cdfs.disk.balancer.block.tolerance.percent.7C_The_tolerance_percent_specifies_when_we_have_reached_a_good_enough_value_for_any_copy_step._For_example.2C_if_you_specify_10.25_then_getting_close_to_10.25_of_the_target_value_is_good_enough..7C_.7Cdfs.disk.balancer.plan.threshold.percent.7C_The_percentage_threshold_value_for_volume_Data_Density_in_a_plan._If_the_absolute_value_of_volume_Data_Density_which_is_out_of_threshold_value_in_a_node.2C_it_means_that_the_volumes_corresponding_to_the_disks_should_do_the_balancing_in_the_plan._The_default_value_is_10..7C_.7Cdfs.disk.balancer.plan.valid.interval.7C_Maximum_amount_of_time_disk_balancer_plan_is_valid._Supports_the_following_suffixes_.28case_insensitive.29:_ms.28millis.29.2C_s.28sec.29.2C_m.28min.29.2C_h.28hour.29.2C_d.28day.29_to_specify_the_time_.28such_as_2s.2C_2m.2C_1h.2C_etc..29._If_no_suffix_is_specified_then_milliseconds_is_assumed._Default_value_is_1d.7C_Debugging">| Setting | Description | |:&#x2014;- |:&#x2014;- | |dfs.disk.balancer.enabled| This parameter controls if diskbalancer is enabled for a cluster. if this is not enabled, any execute command will be rejected by the datanode.The default value is false.| |dfs.disk.balancer.max.disk.throughputInMBperSec | This controls the maximum disk bandwidth consumed by diskbalancer while copying data. If a value like 10MB is specified then diskbalancer on the average will only copy 10MB/S. The default value is 10MB/S.| |dfs.disk.balancer.max.disk.errors| sets the value of maximum number of errors we can ignore for a specific move between two disks before it is abandoned. For example, if a plan has 3 pair of disks to copy between , and the first disk set encounters more than 5 errors, then we abandon the first copy and start the second copy in the plan. The default value of max errors is set to 5.| |dfs.disk.balancer.block.tolerance.percent| The tolerance percent specifies when we have reached a good enough value for any copy step. For example, if you specify 10% then getting close to 10% of the target value is good enough.| |dfs.disk.balancer.plan.threshold.percent| The percentage threshold value for volume Data Density in a plan. If the absolute value of volume Data Density which is out of threshold value in a node, it means that the volumes corresponding to the disks should do the balancing in the plan. The default value is 10.| |dfs.disk.balancer.plan.valid.interval| Maximum amount of time disk balancer plan is valid. Supports the following suffixes (case insensitive): ms(millis), s(sec), m(min), h(hour), d(day) to specify the time (such as 2s, 2m, 1h, etc.). If no suffix is specified then milliseconds is assumed. Default value is 1d| Debugging</a></li></ul>

<div class="section">
<h2><a name="Overview"></a>Overview</h2>
<p>Diskbalancer is a command line tool that distributes data evenly on all disks of a datanode. This tool is different from  <a href="./HdfsUserGuide.html#Balancer">Balancer</a>  which takes care of cluster-wide data balancing. Data can have uneven spread between disks on a node due to several reasons. This can happen due to large amount of writes and deletes or due to a disk replacement. This tool operates against a given datanode and moves blocks from one disk to another.</p></div>
<div class="section">
<h2><a name="Architecture"></a>Architecture</h2>
<p>Disk Balancer operates by creating a plan and goes on to execute that plan on the datanode. A plan is a set of statements that describe how much data should move between two disks. A plan is composed of multiple move steps. A move step has source disk, destination disk and number of bytes to move. A plan can be executed against an operational data node. Disk balancer should not interfere with other processes since it throttles how much data is copied every second. Please note that disk balancer is not enabled by default on a cluster. To enable diskbalancer <tt>dfs.disk.balancer.enabled</tt> must be set to <tt>true</tt> in hdfs-site.xml.</p></div>
<div class="section">
<h2><a name="Commands"></a>Commands</h2>
<p>The following sections discusses what commands are supported by disk balancer and how to use them.</p>
<div class="section">
<h3><a name="Plan"></a>Plan</h3>
<p>The plan command can be run against a given datanode by running</p>
<p><tt>hdfs diskbalancer -plan node1.mycluster.com</tt></p>
<p>The command accepts <a href="../hadoop-common/CommandsManual.html#Generic_Options">Generic Options</a>.</p>
<p>The plan command also has a set of parameters that allows user to control the output and execution of the plan.</p>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th align="left"> COMMAND_OPTION    </th>
<th align="left"> Description </th></tr>
</thead><tbody>

<tr class="b">
<td align="left"> <tt>-out</tt></td>
<td align="left"> Allows user to control the output location of the plan file.</td></tr>
<tr class="a">
<td align="left"> <tt>-bandwidth</tt></td>
<td align="left"> Since datanode is operational and might be running other jobs, diskbalancer limits the amount of data moved per second. This parameter allows user to set the maximum bandwidth to be used. This is not required to be set since diskBalancer will use the default bandwidth if this is not specified.</td></tr>
<tr class="b">
<td align="left"> <tt>-thresholdPercentage</tt></td>
<td align="left"> Since we operate against a snap-shot of datanode, the move operations have a tolerance percentage to declare success. If user specifies 10% and move operation is say 20GB in size, if we can move 18GB that operation is considered successful. This is to accommodate the changes in datanode in real time. This parameter is not needed and a default is used if not specified.</td></tr>
<tr class="a">
<td align="left"> <tt>-maxerror</tt> </td>
<td align="left"> Max error allows users to specify how many block copy operations must fail before we abort a move step. Once again, this is not a needed parameter and a system-default is used if not specified.</td></tr>
<tr class="b">
<td align="left"> <tt>-v</tt></td>
<td align="left"> Verbose mode, specifying this parameter forces the plan command to print out a summary of the plan on stdout.</td></tr>
<tr class="a">
<td align="left"><tt>-fs</tt></td>
<td align="left"> - Specifies the namenode to use. if not specified default from config  is used. </td></tr>
</tbody>
</table>
<p>The plan command writes two output files. They are <tt>&lt;nodename&gt;.before.json</tt> which captures the state of the cluster before the diskbalancer is run, and <tt>&lt;nodename&gt;.plan.json</tt>.</p></div>
<div class="section">
<h3><a name="Execute"></a>Execute</h3>
<p>Execute command takes a plan command executes it against the datanode that plan was generated against.</p>
<p><tt>hdfs diskbalancer -execute /system/diskbalancer/nodename.plan.json</tt></p>
<p>This executes the plan by reading datanode&#x2019;s address from the plan file.</p>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th align="left"> COMMAND_OPTION    </th>
<th align="left"> Description </th></tr>
</thead><tbody>

<tr class="b">
<td align="left"> <tt>-skipDateCheck</tt> </td>
<td align="left">  Skip date check and force execute the plan.</td></tr>
</tbody>
</table></div>
<div class="section">
<h3><a name="Query"></a>Query</h3>
<p>Query command gets the current status of the diskbalancer from a datanode.</p>
<p><tt>hdfs diskbalancer -query nodename.mycluster.com</tt></p>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th align="left"> COMMAND_OPTION </th>
<th align="left"> Description </th></tr>
</thead><tbody>

<tr class="b">
<td align="left"><tt>-v</tt> </td>
<td align="left"> Verbose mode, Prints out status of individual moves</td></tr>
</tbody>
</table></div>
<div class="section">
<h3><a name="Cancel"></a>Cancel</h3>
<p>Cancel command cancels a running plan. Restarting datanode has the same effect as cancel command since plan information on the datanode is transient.</p>
<p><tt>hdfs diskbalancer -cancel /system/diskbalancer/nodename.plan.json</tt></p>
<p>or</p>
<p><tt>hdfs diskbalancer -cancel planID -node nodename</tt></p>
<p>Plan ID can be read from datanode using query command.</p></div>
<div class="section">
<h3><a name="Report"></a>Report</h3>
<p>Report command provides detailed report of specified node(s) or top nodes that will benefit from running disk balancer. The node(s) can be specified by a host file or comma-separated list of nodes.</p>
<p><tt>hdfs diskbalancer -fs http://namenode.uri -report -node &lt;file://&gt; | [&lt;DataNodeID|IP|Hostname&gt;,...]</tt></p>
<p>or</p>
<p><tt>hdfs diskbalancer -fs http://namenode.uri -report -top topnum</tt></p></div></div>
<div class="section">
<h2><a name="Settings"></a>Settings</h2>
<p>There is a set of diskbalancer settings that can be controlled via hdfs-site.xml</p></div>
<div class="section">
<h2><a name="a.7C_Setting_.7C_Description_.7C_.7C:.E2.80.94-_.7C:.E2.80.94-_.7C_.7Cdfs.disk.balancer.enabled.7C_This_parameter_controls_if_diskbalancer_is_enabled_for_a_cluster._if_this_is_not_enabled.2C_any_execute_command_will_be_rejected_by_the_datanode.The_default_value_is_false..7C_.7Cdfs.disk.balancer.max.disk.throughputInMBperSec_.7C_This_controls_the_maximum_disk_bandwidth_consumed_by_diskbalancer_while_copying_data._If_a_value_like_10MB_is_specified_then_diskbalancer_on_the_average_will_only_copy_10MB.2FS._The_default_value_is_10MB.2FS..7C_.7Cdfs.disk.balancer.max.disk.errors.7C_sets_the_value_of_maximum_number_of_errors_we_can_ignore_for_a_specific_move_between_two_disks_before_it_is_abandoned._For_example.2C_if_a_plan_has_3_pair_of_disks_to_copy_between_.2C_and_the_first_disk_set_encounters_more_than_5_errors.2C_then_we_abandon_the_first_copy_and_start_the_second_copy_in_the_plan._The_default_value_of_max_errors_is_set_to_5..7C_.7Cdfs.disk.balancer.block.tolerance.percent.7C_The_tolerance_percent_specifies_when_we_have_reached_a_good_enough_value_for_any_copy_step._For_example.2C_if_you_specify_10.25_then_getting_close_to_10.25_of_the_target_value_is_good_enough..7C_.7Cdfs.disk.balancer.plan.threshold.percent.7C_The_percentage_threshold_value_for_volume_Data_Density_in_a_plan._If_the_absolute_value_of_volume_Data_Density_which_is_out_of_threshold_value_in_a_node.2C_it_means_that_the_volumes_corresponding_to_the_disks_should_do_the_balancing_in_the_plan._The_default_value_is_10..7C_.7Cdfs.disk.balancer.plan.valid.interval.7C_Maximum_amount_of_time_disk_balancer_plan_is_valid._Supports_the_following_suffixes_.28case_insensitive.29:_ms.28millis.29.2C_s.28sec.29.2C_m.28min.29.2C_h.28hour.29.2C_d.28day.29_to_specify_the_time_.28such_as_2s.2C_2m.2C_1h.2C_etc..29._If_no_suffix_is_specified_then_milliseconds_is_assumed._Default_value_is_1d.7C_Debugging"></a>| Setting | Description | |:&#x2014;- |:&#x2014;- | |<tt>dfs.disk.balancer.enabled</tt>| This parameter controls if diskbalancer is enabled for a cluster. if this is not enabled, any execute command will be rejected by the datanode.The default value is false.| |<tt>dfs.disk.balancer.max.disk.throughputInMBperSec</tt> | This controls the maximum disk bandwidth consumed by diskbalancer while copying data. If a value like 10MB is specified then diskbalancer on the average will only copy 10MB/S. The default value is 10MB/S.| |<tt>dfs.disk.balancer.max.disk.errors</tt>| sets the value of maximum number of errors we can ignore for a specific move between two disks before it is abandoned. For example, if a plan has 3 pair of disks to copy between , and the first disk set encounters more than 5 errors, then we abandon the first copy and start the second copy in the plan. The default value of max errors is set to 5.| |<tt>dfs.disk.balancer.block.tolerance.percent</tt>| The tolerance percent specifies when we have reached a good enough value for any copy step. For example, if you specify 10% then getting close to 10% of the target value is good enough.| |<tt>dfs.disk.balancer.plan.threshold.percent</tt>| The percentage threshold value for volume Data Density in a plan. If the absolute value of volume Data Density which is out of threshold value in a node, it means that the volumes corresponding to the disks should do the balancing in the plan. The default value is 10.| |<tt>dfs.disk.balancer.plan.valid.interval</tt>| Maximum amount of time disk balancer plan is valid. Supports the following suffixes (case insensitive): ms(millis), s(sec), m(min), h(hour), d(day) to specify the time (such as 2s, 2m, 1h, etc.). If no suffix is specified then milliseconds is assumed. Default value is 1d| Debugging</h2>
<p>Disk balancer generates two output files. The nodename.before.json contains the state of cluster that we read from the  namenode. This file contains detailed information about  datanodes and volumes.</p>
<p>if you plan to post this file to an apache JIRA, you might want to replace your hostnames and volume paths since it may leak your personal information.</p>
<p>You can also trim this file down to focus only on the nodes that you want to report in the JIRA.</p>
<p>The nodename.plan.json contains the plan for the specific node. This plan file contains as a series of steps. A step is executed as a series of move operations inside the datanode.</p>
<p>To diff the state of a node before and after, you can either re-run a plan command and diff the new nodename.before.json with older before.json or run report command against the node.</p>
<p>To see the progress of a running plan, please run query command with option -v. This will print out a set of steps &#x2013; Each step represents a move operation from one disk to another.</p>
<p>The speed of move is limited by the bandwidth that is specified. The default value of bandwidth is set to 10MB/sec. if you do a query with -v option you will see the following values.</p>

<div>
<div>
<pre class="source">  &quot;sourcePath&quot; : &quot;/data/disk2/hdfs/dn&quot;,

  &quot;destPath&quot; : &quot;/data/disk3/hdfs/dn&quot;,

  &quot;workItem&quot; :

    &quot;startTime&quot; : 1466575335493,

    &quot;secondsElapsed&quot; : 16486,

    &quot;bytesToCopy&quot; : 181242049353,

    &quot;bytesCopied&quot; : 172655116288,

    &quot;errorCount&quot; : 0,

    &quot;errMsg&quot; : null,

    &quot;blocksCopied&quot; : 1287,

    &quot;maxDiskErrors&quot; : 5,

    &quot;tolerancePercent&quot; : 10,

    &quot;bandwidth&quot; : 10
</pre></div></div>

<p><i>source path</i> - is the volume we are copying from.</p>
<p><i>dest path</i> - is the volume to where we are copying to.</p>
<p><i>start time</i> - is current time in milliseconds.</p>
<p><i>seconds elapsed</i> - is updated whenever we update the stats. This might be slower than the wall clock time.</p>
<p><i>bytes to copy</i> - is number of bytes we are supposed to copy. We copy plus or minus a certain percentage. So often you will see bytesCopied &#x2013; as a value lesser than bytes to copy. In the default case, getting within 10% of bytes to move is considered good enough.</p>
<p><i>bytes copied</i> - is the actual number of bytes that we moved from source disk to destination disk.</p>
<p><i>error count</i> - Each time we encounter an error we will increment the error count. As long as error count remains less than max error count (default value is 5), we will try to complete this move. if we hit the max error count we will abandon this current step and execute the next step in the plan.</p>
<p><i>error message</i> - Currently a single string that reports the last error message. Older messages should be in the datanode log.</p>
<p><i>blocks copied</i> - Number of blocks copied.</p>
<p><i>max disk errors</i> - The configuration used for this move step. currently it will report the default config value, since the user interface to control these values per step is not in place. It is a future work item. The default or the command line value specified in plan command is used for this value.</p>
<p><i>tolerance percent</i> - This represents how much off we can be while moving data. In a busy cluster this allows admin to say, compute a plan, but I know this node is being used so it is okay if disk balancer can reach +/- 10% of the bytes to be copied.</p>
<p><i>bandwidth</i> - This is the maximum aggregate source disk bandwidth used by the disk balancer. After moving a block disk balancer computes how many seconds it should have taken to move that block with the specified bandwidth. If the actual move took less time than expected, then disk balancer will sleep for that duration. Please note that currently all moves are executed sequentially by a single thread.</p></div>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
        &#169;            2008-2018
              Apache Software Foundation
            
                          - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a>.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
