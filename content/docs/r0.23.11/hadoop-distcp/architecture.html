<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- Generated by Apache Maven Doxia at Jun 19, 2014 -->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>
        Architecture of DistCp</title>
    <style type="text/css" media="all">
      @import url("./css/maven-base.css");
      @import url("./css/maven-theme.css");
      @import url("./css/site.css");
    </style>
    <link rel="stylesheet" href="./css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20140619" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      </head>
  <body class="composite">
    <div id="banner">
                  <a href="https://hadoop.apache.org/" id="bannerLeft">
                                        <img src="https://hadoop.apache.org/images/hadoop-logo.jpg" alt="" />
                </a>
                        <a href="https://www.apache.org/" id="bannerRight">
                                        <img src="https://www.apache.org/images/asf_logo_wide.png" alt="" />
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                <div class="xleft">
                          <a href="https://www.apache.org/" class="externalLink">Apache</a>
                &gt;
                      <a href="https://hadoop.apache.org/" class="externalLink">Hadoop</a>
                &gt;
                Apache Hadoop Distributed Copy
                </div>
            <div class="xright">            <a href="https://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://svn.apache.org/repos/asf/hadoop/" class="externalLink">SVN</a>
              
                                &nbsp;| Last Published: 2014-06-19
              &nbsp;| Version: 0.23.11
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                <h5>Common</h5>
                  <ul>
                  <li class="none">
                  <a href="../index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/ClusterSetup.html">Cluster Setup</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/FileSystemShell.html">File System Shell</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/NativeLibraries.html">Native Libraries</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/Superusers.html">Superusers</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/CommandsManual.html">Hadoop Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/ServiceLevelAuth.html">Service Level Authorization</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/HttpAuthentication.html">HTTP Authentication</a>
            </li>
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">HDFS User Guide</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/Federation.html">Federation</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">HDFS Architecture</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html">Edits Viewer</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html">Image Viewer</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">Permissions and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html">Quotas and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/Hftp.html">HFTP</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/LibHdfs.html">C API libhdfs</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS REST API</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-hdfs-httpfs/index.html">HttpFS Gateway</a>
            </li>
          </ul>
                       <h5>MapReduce/YARN</h5>
                  <ul>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/YARN.html">YARN Architecture</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html">Writing YARN Applications</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html">Web Application Proxy</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/YarnCommands.html">YARN Commands</a>
            </li>
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html">Introduction</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html">Resource Manager</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/NodeManagerRest.html">Node Manager</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/MapredAppMasterRest.html">MR Application Master</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-site/HistoryServerRest.html">History Server</a>
            </li>
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  <li class="none">
                  <a href="../hadoop-auth/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-auth/Examples.html">Examples</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-auth/Configuration.html">Configuration</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-auth/BuildingIt.html">Building</a>
            </li>
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/releasenotes.html">Release Notes</a>
            </li>
                  <li class="none">
                  <a href="../api/index.html">API docs</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/CHANGES.txt">Common CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/CHANGES.txt">HDFS CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-mapreduce/CHANGES.txt">MapReduce CHANGES.txt</a>
            </li>
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../hadoop-project-dist/hadoop-common/DeprecatedProperties.html">Deprecated Properties</a>
            </li>
          </ul>
                                 <a href="https://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="./images/logos/maven-feather.png"/>
        </a>
                       
                            </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!-- Copyright 2002-2004 The Apache Software Foundation

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      https://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. -->
    
      <div class="section"><h2>Architecture<a name="Architecture"></a></h2>

        <p>The components of the new DistCp may be classified into the following
           categories: </p>

        <ul>

          <li>DistCp Driver</li>
          <li>Copy-listing generator</li>
          <li>Input-formats and Map-Reduce components</li>

        </ul>

        <div class="section"><h3>DistCp Driver<a name="DistCp_Driver"></a></h3>
          <p>The DistCp Driver components are responsible for:</p>

          <ul>
            <li>Parsing the arguments passed to the DistCp command on the
                command-line, via:
              <ul>
                <li>OptionsParser, and</li>
                <li>DistCpOptionsSwitch</li>
              </ul>
            </li>
            <li>Assembling the command arguments into an appropriate
                DistCpOptions object, and initializing DistCp. These arguments
                include:
              <ul>
                <li>Source-paths</li>
                <li>Target location</li>
                <li>Copy options (e.g. whether to update-copy, overwrite, which
                    file-attributes to preserve, etc.)</li>
              </ul>
            </li>
            <li>Orchestrating the copy operation by:
              <ul>
                <li>Invoking the copy-listing-generator to create the list of
                    files to be copied.</li>
                <li>Setting up and launching the Hadoop Map-Reduce Job to carry
                    out the copy.</li>
                <li>Based on the options, either returning a handle to the
                    Hadoop MR Job immediately, or waiting till completion.</li>
              </ul>
            </li>
          </ul>
          <br />

          <p>The parser-elements are exercised only from the command-line (or if
             DistCp::run() is invoked). The DistCp class may also be used
             programmatically, by constructing the DistCpOptions object, and
             initializing a DistCp object appropriately.</p>

        </div>

        <div class="section"><h3>Copy-listing generator<a name="Copy-listing_generator"></a></h3>

          <p>The copy-listing-generator classes are responsible for creating the
             list of files/directories to be copied from source. They examine
             the contents of the source-paths (files/directories, including
             wild-cards), and record all paths that need copy into a sequence-
             file, for consumption by the DistCp Hadoop Job. The main classes in
             this module include:</p>

          <ol style="list-style-type: decimal">

            <li>CopyListing: The interface that should be implemented by any 
                copy-listing-generator implementation. Also provides the factory
                method by which the concrete CopyListing implementation is
                chosen.</li>

            <li>SimpleCopyListing: An implementation of CopyListing that accepts
                multiple source paths (files/directories), and recursively lists
                all the individual files and directories under each, for
                copy.</li>

            <li>GlobbedCopyListing: Another implementation of CopyListing that
                expands wild-cards in the source paths.</li>

            <li>FileBasedCopyListing: An implementation of CopyListing that
                reads the source-path list from a specified file.</li>

          </ol>
          <p></p>

          <p>Based on whether a source-file-list is specified in the
             DistCpOptions, the source-listing is generated in one of the
             following ways:</p>

          <ol style="list-style-type: decimal">

            <li>If there's no source-file-list, the GlobbedCopyListing is used.
                All wild-cards are expanded, and all the expansions are
                forwarded to the SimpleCopyListing, which in turn constructs the
                listing (via recursive descent of each path). </li>

            <li>If a source-file-list is specified, the FileBasedCopyListing is
                used. Source-paths are read from the specified file, and then
                forwarded to the GlobbedCopyListing. The listing is then
                constructed as described above.</li>

          </ol>

          <br />

          <p>One may customize the method by which the copy-listing is
             constructed by providing a custom implementation of the CopyListing
             interface. The behaviour of DistCp differs here from the legacy
             DistCp, in how paths are considered for copy. </p>

          <p>The legacy implementation only lists those paths that must
             definitely be copied on to target.
             E.g. if a file already exists at the target (and -overwrite isn't
             specified), the file isn't even considered in the Map-Reduce Copy
             Job. Determining this during setup (i.e. before the Map-Reduce Job)
             involves file-size and checksum-comparisons that are potentially
             time-consuming.</p>

          <p>The new DistCp postpones such checks until the Map-Reduce Job, thus
             reducing setup time. Performance is enhanced further since these
             checks are parallelized across multiple maps.</p>

        </div>

        <div class="section"><h3>Input-formats and Map-Reduce components<a name="Input-formats_and_Map-Reduce_components"></a></h3>

          <p> The Input-formats and Map-Reduce components are responsible for
              the actual copy of files and directories from the source to the
              destination path. The listing-file created during copy-listing
              generation is consumed at this point, when the copy is carried
              out. The classes of interest here include:</p>

          <ul>
            <li><b>UniformSizeInputFormat:</b> This implementation of
                org.apache.hadoop.mapreduce.InputFormat provides equivalence
                with Legacy DistCp in balancing load across maps.
                The aim of the UniformSizeInputFormat is to make each map copy
                roughly the same number of bytes. Apropos, the listing file is
                split into groups of paths, such that the sum of file-sizes in
                each InputSplit is nearly equal to every other map. The splitting
                isn't always perfect, but its trivial implementation keeps the
                setup-time low.</li>

            <li><b>DynamicInputFormat and DynamicRecordReader:</b>
                <p> The DynamicInputFormat implements org.apache.hadoop.mapreduce.InputFormat,
                and is new to DistCp. The listing-file is split into several
                &quot;chunk-files&quot;, the exact number of chunk-files being a multiple
                of the number of maps requested for in the Hadoop Job. Each map
                task is &quot;assigned&quot; one of the chunk-files (by renaming the chunk
                to the task's id), before the Job is launched.</p>

                <p>Paths are read from each chunk using the DynamicRecordReader,
                and processed in the CopyMapper. After all the paths in a chunk
                are processed, the current chunk is deleted and a new chunk is
                acquired. The process continues until no more chunks are
                available.</p>
                <p>This &quot;dynamic&quot; approach allows faster map-tasks to consume
                more paths than slower ones, thus speeding up the DistCp job
                overall. </p>
            </li>

            <li><b>CopyMapper:</b> This class implements the physical
                file-copy. The input-paths are checked against the input-options
                (specified in the Job's Configuration), to determine whether a
                file needs copy. A file will be copied only if at least one of
                the following is true:
              <ul>
                <li>A file with the same name doesn't exist at target.</li>
                <li>A file with the same name exists at target, but has a
                    different file size.</li>
                <li>A file with the same name exists at target, but has a
                    different checksum, and -skipcrccheck isn't mentioned.</li>
                <li>A file with the same name exists at target, but -overwrite
                    is specified.</li>
                <li>A file with the same name exists at target, but differs in
                    block-size (and block-size needs to be preserved.</li>
              </ul>
            </li>

            <li><b>CopyCommitter:</b>
                This class is responsible for the commit-phase of the DistCp
                job, including:
              <ul>
                <li>Preservation of directory-permissions (if specified in the
                    options)</li>
                <li>Clean-up of temporary-files, work-directories, etc.</li>
              </ul>
            </li>
          </ul>
        </div>
      </div>
    

      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">&#169;            2014
              Apache Software Foundation
            
                       - <a href="https://maven.apache.org/privacy-policy.html">Privacy Policy</a></div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
